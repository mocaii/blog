---
title: 初识人工智能
date: '2024-05-14T10:26:49.833Z'
lastModified: '2024-05-14T10:26:49.833Z'
---
# 初识人工智能

## 一、概念

### 1. 图灵测试

**判断是否为人工智能的测试**：评估机器是否能展示出与人类无法区分的智能行为。

### 2. Transformer

**基于自注意力机制的深度学习模型**：核心在于自注意力机制，有效处理序列数据。

### 3. 自注意力机制

**Self-Attention**：主要思想是在处理序列的每个元素时，不仅考虑该元素本身，还考虑其他相关的元素。在序列处理中同时考虑每个元素及其与序列中其他元素的关系。

### 4. 多模态

能够处理多种类型的数据，如文本、图像、视频和音乐。

### 5. Token

自然语言处理的基本单元，类似于词汇。

### 6. 神经网络

- **前馈神经网络**：数据流向单一方向，无反馈。一直往前不回头。
- **反馈神经网络**：具备反馈机制，可以对输出进行调整。先听，后回应。
- **卷积神经网络**：擅长图像处理，过滤无关信息。过滤不重要的数据。
- **递归神经网络**：适合序列数据，有循环连接。

### 7. 深度学习

- 机器利用多个层次的非线性变换，从大量数据中自动学习特征并进行决策。通过多层非线性变换从数据中学习，实现特征提取与决策。
- **神经网络的高级应用**。

## 二、分类

### 1. 按任务类型

- 强化学习
- 图像生成
- 图像识别
- 语言识别

### 2. 按学习方式

- **强化学习** (Reinforcement Learning)： 通过与环境交互学习最大化奖励。通过探索和学习，与外部环境交互，从而获得最大的累积奖励。
- **监督学习** (Supervised Learning)： 需要标签数据。标记数据，人类干预。
- 半监督学习
- **自监督学习** (Self-supervised Learning)： 无需人工标注数据。

### 3. 按应用领域

- NLP (自然语言处理)
- CV (计算机视觉)
- 推荐系统
- 智能控制
- 语音识别
- 机器翻译

### 4. 按模型类型

- 逻辑回归
- 神经网络
- 决策树
- 支持向量机
- 随机森林
- 朴素贝叶斯

## 三、工作原理

1. 数据收集
2. 数据处理
3. 模型训练
4. 模型评估
5. 部署和应用

## 四、语言模型

Language Modal，对词序的生成可能性进行建模，以预测未来 Token 的概率。

### 1. 统计语言模型

- Statistical Language Modal，自然语言模型的基础模型，从概率统计角度出发，解决自然语言上下文相关的特性，如根据最近的上下文预测下一个词。
- 基于概率统计预测下一个词。

### 2. 神经语言模型

- Neural Language Modal，使用神经网络表达词序列概率。

### 3. 预训练语言模型

- **Pre-trained Language Models**: 利用大量数据预训练得到初始参数。
- 模型参数不再是随机初始化的，而是通过一些任务进行了预先训练，得到一套模型参数，通过这些参数再对模型进行训练。

### 4. 大语言模型

- **Large Language Models (LLMs)**: 规模增大和数据量提升模型性能。在预训练语言模型的研究过程中，研究人员发现，增加模型大小和数据量可以提高下游任务的完成质量。

## 五、生成式 AI 模型

### 1. 变分自编码器

VAE，Variational Autoencoder，学习输入数据的潜在分布，并从这个分布中生成新的数据

### 2. 生成式对抗网络

GAN，Generative Adversarial Network，深度学习模型

### 3. 卷积生成式对抗网络

CGAN，Convolutional Generative Adversarial Network

### 4. 条件生成式对抗网络

cGAN，Condtional Generative Adversarial Network

### 5. Transformer 深度神经网络

- 自注意力机制
- 多头注意力
- 长距离依赖性建模能力
- 预训练：通过海量文本数据进行自监督学习
- 微调：根据特定的训练数据进行监督学习微调

## 六、自然语言处理任务

### 1. 文本摘要

Text Summarization，长文生成摘要

### 2. 文本纠错

Text Correction，拼写、语法、用法纠错

### 3. 情感分析

Sentiment Analysis，分析产品评论

### 4. 命名实体识别

Named Entity Recognition，文本中识别出人名、地名等

### 5. 机器翻译

Machine Translation，翻译国外论文，实时翻译等

### 6. 关键词抽取

Keyword Extraction，为论文生成关键词，优化 SEO

### 7. 问题回答

Question Answering

### 8. 生成式任务

Generative Tasks，写文章、写演讲稿、创作

## 七、模型类型

- GANs
- Transformers
- Diffusion
- CLIP
- LLMs (Large Language Modal，大语言模型)

## 八、大模型

### 1. 千帆（百度）

#### 行业

- ChatLaw 法律大模型
- 度小满轩辕-金融大模型：基于 meta 的 Llama2-70B
- DISC-MedLLM 复旦医疗健康大模型

#### 全能

- ERNIE-Bot 4.0：文心大模型
-     ERNIE-Bot

#### 文图生成

- Stable-Diffusion-XL：基于 Stability AI 研发的文生图大模型

#### 文本对话/创作续写

- 千帆中文增强版 Llama-2-7B/13B：基于 meta 的 llama
- ERNIE-Bot-turbo
- ...

#### 代码生成

- SQLCoder：基于 Mistral-7B，DeFog.ai
- Code Llama：基于 meta 的 Code Llama ，超越原生 llama
- 智源 AquilaCode-multi
- StarCoder

#### 文本表征

- 智源 bge-large
- Embeddings_V1

### 2. Meta (Facebook)

- Llama
- Code Llama

### 3. OpenAI

- chatGPT 1：2018，1.17 亿参数，基本问答，模型结构 Transformer Decoder

- chatGPT 2：2019，15 亿参数，自然连贯，单次处理数据量 1024Tokens

- chatGPT 3：2020，1750 亿参数，复杂任务与专家知识，单次处理数据量 2048Tokens

- chatGPT 3.5：2022.11.30 发布，2023.2 对外开放，单次处理数据量 4096Tokens

- chatGPT-3.5-Turbo：2023.3.2 发布，单次处理数据量 4096Tokens

- chatGPT 4：2023.3.14 发布，最大单次 2.5 万 tokens，性能比 gpt3 提升 500 多倍，多模态

### 4. 通义（阿里）

- 通义千问：问答助手，可解析图片/文档
- 通义万相：智能绘画创作
- 通义灵码：编程助手
- 通义听悟：音视频转文字，支持实时
- 通义星辰：角色扮演聊天，恋爱伴侣，英语老师等
- 通义晓蜜：智能对话机器人接入
- 通义点金：金融分析
- 通义法睿：法律顾问
- 通义仁心：健康助手
- 通义智文：阅读助手，自动帮你总结，还可以做笔记，提问

## 九、Prompt

### 1. 提示

用户向人工智能提供的输入信息，这些信息通常包含关键词、问题或指令

### 2. 提示工程

通过精心设计、优化输入信息（提示），来引导人工智能生成高质量、准确、有针对性的回应

### 3. 用 AI 改造工作

- 拆解：复杂问题简单化
- 标准化：简单问题标准化
- 流程化：标准问题流程化

### 4. chatGPT 基础技巧

- 使用文本分隔符分割指令和上下文，##、“”
- 使用标记语言标记输入格式，**重点内容**（加粗）
- 使用有序列表（1，2，3）与无序列表（-）列出不同的项
- 量化要求（最好是明确的数字）
- 不要说“不要做什么”，要说“要做什么”
- 利用 ChatGPT“接龙”的特性引导下一步
- 多轮对话：保持与 ChatGPT 的对话主题的连贯性；在不同的对话讨论不同的事情
- 使用插件

## 十、自然语言处理技术细节

懂人话。让计算机理解、分析、处理人类自然语言。语音识别、文本分类、信息提取、文本生成、机器翻译、情感分析等。

### 1. 分词

#### 基于规则的分词算法

- 正向最大匹配算法
- 逆向最大匹配算法
- 双向最大匹配算法
- 基于词典的分词算法

#### 基于统计的分词算法

- 隐马尔可夫模型分词，Hidden Markov Model，HMM
- 最大匹配算法
- 基于条件随机场（CRF，Conditional Random Field）的分词算法
- 基于深度学习的分词算法：
  - 卷积神经网络，CNN
  - 循环神经网络，RNN
  - Transformer

#### 性能指标

- 准确率，precision
- 召回率，recall

### 2. 关键词提取

#### 基于词频（Term Frequency，TF）的方法

- 常规词频算法
- 停用词过滤算法：“的”，“了”，“是”
- 词频算法

#### 基于 TF-IDF 的方法

- 词频-逆向文件频率，TF-IDF，Term Frequency-Inverse Document Frequency
- TextRank 算法，文本排序
- RAKE 算法，Rapid Automatic Keyword Extraction，快速自动关键字提取
- TF-IDF-IR，Term Frequency-Inverse Document Frequency-Information Retrieval，词频-逆文档频率信息检索

#### 基于主题模型的方法

- 潜在词法分析，Latent Semantic Analysis，LSA
- 潜在狄利克雷分配算法，Latent Dirichlet Allocation，LDA
- 层次狄利克雷过程，Hierarchical Dirichlet Process，HDP
- 二项式词对主题模型，Biterm Topic Model，BTM

#### 基于深度学习的方法

- TextRank+Word2Vec
- RNN+Attention
- Seq2Seq+RL
- 图卷积网络，Graph Convolutional Network，GCN
- 图注意力网络，Graph Attention Network，GAN
- 层次注意力网络，Hierarchical Attention Network，HAN

### 3. 摘要提取

#### 基于统计的算法

- 基于 TF-IDF 的摘要提取算法
- TextRank 算法，文本排序
- 潜在词法分析，Latent Semantic Analysis，LSA
- LexRank 算法

#### 基于机器学习的算法

- 支持向量机，Support Vector Machine，SVM，监督学习算法
- 随机森林算法
- 聚类算法，非监督学习算法

#### 基于深度学习的算法

- Seq2Seq 模型
- Transformer 模型，注意力机制
- Pointer-Generator 模型
- 强化学习，Reinforcement Learning，RL。RL 模型通过模拟人类的行为方式，基于奖励机制训练模型。

#### 性能指标

- ROUFE 分数，Recall-Oriented Understudy for Gisting Evaluation
- BLEU 分数
- F1 值

### 4. 流程

对话系统-->文本预处理-->分词、词性标注-->命名实体识别-->实体关系提取-->情感分析-->机器翻译--文本生成

## Transformer 架构

- 神经网络架构
- 自注意力机制，Self-attention mechanism，以自己为对照，将自己的注意力进行计算
- 前馈神经网络，Feedforward Neural Network，FNN
- 编码器 Encoder，将输入文本编码成向量表示
- 解码器 Decoder，将向量表示解码成输出文本
- 预训练，在大规模文本数据上自监督地训练一个编码器，以便为下游任务提供更好的初始权重。训练方法：
  - 掩码语言建模，Masked Language Modeling，MLM
  - 下一句预测，Next Sentence Prediction，NSP
- 微调，Fine-tuning，在预训练模型的基础上，通过少量的训练数据和特定的目标函数去进一步优化模型，使其适用于特定任务。策略：

  - 适当添加头部层，Task-specific Head
  - 采用不同的损失函数
  - 调整学习率
  - 增加数据集的噪声

## 十一、名词解释

- GPT：Generative Pre-trained Transformer，生成式预训练转换模型，基于 Transformer 模型的、在大规模数据集上进行预训练的、用于生成文本的深度学习模型。
- LLM：Large Language Modal，大语言模型
- NLP：Natural Language Processing，自然语言处理（语音识别、语音合成、语义理解、机器翻译）
- AGI：Artificial General Intelligence，通用人工智能
- AIGC：Artificial Intelligence Generated Content，人工智能生成内容
- CNN：卷积神经网络
- RNN：循环神经网络
- GAN：生成对抗网络
